{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA PM2 - Dataset pre-filtering\n",
    "\n",
    "This notebooks aims at pre-filtering the [YouNiverse](https://zenodo.org/records/4650046) dataset to only keep gaming related content. In the detail, we will proceed following the next steps.\n",
    "1. Keep only videos which `category` is `Gaming`.\n",
    "2. Keep only channels which have at least one video in the selected list.\n",
    "3. Keep only time-series for the selected channels.\n",
    "4. Keep only comments for the selected videos.\n",
    "\n",
    "We will export each of the resulting datasets in a separate `.tsv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "ORIGINAL_PATH = {\n",
    "    \"videos\": \"../data/youniverse/original/yt_metadata_en.jsonl\",\n",
    "    \"channels\": \"../data/youniverse/original/df_channels_en.tsv\",\n",
    "    \"timeseries\": \"../data/youniverse/original/df_timeseries_en.tsv\",\n",
    "    \"comments\": \"../data/youniverse/original/youtube_comments.tsv\"\n",
    "}\n",
    "\n",
    "FILTERED_PATH = {\n",
    "    \"videos\": \"../data/youniverse/filtered/gaming_videos.tsv\",\n",
    "    \"channels\": \"../data/youniverse/filtered/gaming_channels.tsv\",\n",
    "    \"timeseries\": \"../data/youniverse/filtered/gaming_timeseries.tsv\",\n",
    "    \"comments\": \"../data/youniverse/filtered/gaming_comments.tsv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos\n",
    "As a first step, let's simply grasp the first lines of our dataset so as to understand its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>categories</th><th>channel_id</th><th>crawl_date</th><th>description</th><th>dislike_count</th><th>display_id</th><th>duration</th><th>like_count</th><th>tags</th><th>title</th><th>upload_date</th><th>view_count</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Film &amp; Animation&quot;</td><td>&quot;UCzWrhkg9eK5I8Bm3HfV-unA&quot;</td><td>&quot;2019-10-31 20:19:26.270363&quot;</td><td>&quot;Lego City Police Lego Firetruc…</td><td>1.0</td><td>&quot;SBqSc91Hn9g&quot;</td><td>1159</td><td>8.0</td><td>&quot;lego city,lego police,lego cit…</td><td>&quot;Lego City Police Lego Firetruc…</td><td>&quot;2016-09-28 00:00:00&quot;</td><td>1057.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 12)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ categorie ┆ channel_i ┆ crawl_dat ┆ descripti ┆ … ┆ tags      ┆ title     ┆ upload_da ┆ view_cou │\n",
       "│ s         ┆ d         ┆ e         ┆ on        ┆   ┆ ---       ┆ ---       ┆ te        ┆ nt       │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ str       ┆ str       ┆ ---       ┆ ---      │\n",
       "│ str       ┆ str       ┆ str       ┆ str       ┆   ┆           ┆           ┆ str       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ Film &    ┆ UCzWrhkg9 ┆ 2019-10-3 ┆ Lego City ┆ … ┆ lego      ┆ Lego City ┆ 2016-09-2 ┆ 1057.0   │\n",
       "│ Animation ┆ eK5I8Bm3H ┆ 1 20:19:2 ┆ Police    ┆   ┆ city,lego ┆ Police    ┆ 8         ┆          │\n",
       "│           ┆ fV-unA    ┆ 6.270363  ┆ Lego      ┆   ┆ police,le ┆ Lego      ┆ 00:00:00  ┆          │\n",
       "│           ┆           ┆           ┆ Firetruc… ┆   ┆ go cit…   ┆ Firetruc… ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_ndjson(ORIGINAL_PATH[\"videos\"], n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only want to get **gaming videos**, we need to filter out this category from our dataset. At the same time, we filter out the columns that are not relevant for our analysis. According to our understanding of the dataset, we will keep the following columns :\n",
    "- `title` and `tags`, which contain useful information about the video content\n",
    "- `upload_date`, which may be useful to track the link between subjects and periods\n",
    "- `view_count`, `like_count` and `dislike_count`, which are key indicators of the video popularity\n",
    "- `duration`, which may be useful to track trends per video game\n",
    "- `channel_id` and `display_id`, which are useful to link videos to channels and comments\n",
    "\n",
    "We drop the `description` column, as it is too heavy to handle over that many videos. We also drop the `categories` column, which is no longer relevant, as well as the `crawl_date` column which is not usefult for our study. Finally, we fill missing values for `tags` with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>title</th><th>tags</th><th>upload_date</th><th>view_count</th><th>like_count</th><th>dislike_count</th><th>duration</th><th>channel_id</th><th>display_id</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Lego City Lego Police1 Hour Lo…</td><td>&quot;lego city,lego police,lego cit…</td><td>&quot;2016-09-26 00:00:00&quot;</td><td>1253.0</td><td>9.0</td><td>0.0</td><td>3442</td><td>&quot;UCzWrhkg9eK5I8Bm3HfV-unA&quot;</td><td>&quot;y5IvyZlzELs&quot;</td></tr><tr><td>&quot;Lego City Police Lego Fireman …</td><td>&quot;lego city,lego police,lego cit…</td><td>&quot;2016-09-25 00:00:00&quot;</td><td>2311.0</td><td>8.0</td><td>0.0</td><td>2407</td><td>&quot;UCzWrhkg9eK5I8Bm3HfV-unA&quot;</td><td>&quot;m1agc0qT0BY&quot;</td></tr><tr><td>&quot;Lego Dimensions Cartoons Movie…</td><td>&quot;lego city,lego dimensions,lego…</td><td>&quot;2016-09-24 00:00:00&quot;</td><td>5596.0</td><td>11.0</td><td>1.0</td><td>1820</td><td>&quot;UCzWrhkg9eK5I8Bm3HfV-unA&quot;</td><td>&quot;rr6tfbBA9iY&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 9)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬──────────┬───────────┬───────────┐\n",
       "│ title     ┆ tags      ┆ upload_da ┆ view_coun ┆ … ┆ dislike_c ┆ duration ┆ channel_i ┆ display_i │\n",
       "│ ---       ┆ ---       ┆ te        ┆ t         ┆   ┆ ount      ┆ ---      ┆ d         ┆ d         │\n",
       "│ str       ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ i64      ┆ ---       ┆ ---       │\n",
       "│           ┆           ┆ str       ┆ f64       ┆   ┆ f64       ┆          ┆ str       ┆ str       │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ Lego City ┆ lego      ┆ 2016-09-2 ┆ 1253.0    ┆ … ┆ 0.0       ┆ 3442     ┆ UCzWrhkg9 ┆ y5IvyZlzE │\n",
       "│ Lego      ┆ city,lego ┆ 6         ┆           ┆   ┆           ┆          ┆ eK5I8Bm3H ┆ Ls        │\n",
       "│ Police1   ┆ police,le ┆ 00:00:00  ┆           ┆   ┆           ┆          ┆ fV-unA    ┆           │\n",
       "│ Hour Lo…  ┆ go cit…   ┆           ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "│ Lego City ┆ lego      ┆ 2016-09-2 ┆ 2311.0    ┆ … ┆ 0.0       ┆ 2407     ┆ UCzWrhkg9 ┆ m1agc0qT0 │\n",
       "│ Police    ┆ city,lego ┆ 5         ┆           ┆   ┆           ┆          ┆ eK5I8Bm3H ┆ BY        │\n",
       "│ Lego      ┆ police,le ┆ 00:00:00  ┆           ┆   ┆           ┆          ┆ fV-unA    ┆           │\n",
       "│ Fireman … ┆ go cit…   ┆           ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "│ Lego Dime ┆ lego      ┆ 2016-09-2 ┆ 5596.0    ┆ … ┆ 1.0       ┆ 1820     ┆ UCzWrhkg9 ┆ rr6tfbBA9 │\n",
       "│ nsions    ┆ city,lego ┆ 4         ┆           ┆   ┆           ┆          ┆ eK5I8Bm3H ┆ iY        │\n",
       "│ Cartoons  ┆ dimension ┆ 00:00:00  ┆           ┆   ┆           ┆          ┆ fV-unA    ┆           │\n",
       "│ Movie…    ┆ s,lego…   ┆           ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_keep = [\n",
    "    \"categories\",\n",
    "    \"title\",\n",
    "    \"tags\",\n",
    "    \"upload_date\",\n",
    "    \"view_count\",\n",
    "    \"like_count\",\n",
    "    \"dislike_count\",\n",
    "    \"duration\",\n",
    "    \"channel_id\",\n",
    "    \"display_id\",\n",
    "]\n",
    "\n",
    "filtered_videos_df = (\n",
    "    pl.read_ndjson(ORIGINAL_PATH[\"videos\"])\n",
    "    .select(columns_to_keep)\n",
    "    .filter(pl.col(\"categories\") == \"Gaming\")\n",
    "    .fill_null(\"\")\n",
    "    .drop(\"categories\")\n",
    ")\n",
    "filtered_videos_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can convert our DataFrame to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_videos_df.write_csv(FILTERED_PATH[\"videos\"], separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels\n",
    "\n",
    "Let's see what this dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>category_cc</th><th>join_date</th><th>channel</th><th>name_cc</th><th>subscribers_cc</th><th>videos_cc</th><th>subscriber_rank_sb</th><th>weights</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;Gaming&quot;</td><td>&quot;2010-04-29&quot;</td><td>&quot;UC-lHJZR3Gqxm24_Vd_AJ5Yw&quot;</td><td>&quot;PewDiePie&quot;</td><td>101000000</td><td>3956</td><td>3.0</td><td>2.087</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 8)\n",
       "┌────────────┬────────────┬────────────┬───────────┬────────────┬───────────┬────────────┬─────────┐\n",
       "│ category_c ┆ join_date  ┆ channel    ┆ name_cc   ┆ subscriber ┆ videos_cc ┆ subscriber ┆ weights │\n",
       "│ c          ┆ ---        ┆ ---        ┆ ---       ┆ s_cc       ┆ ---       ┆ _rank_sb   ┆ ---     │\n",
       "│ ---        ┆ str        ┆ str        ┆ str       ┆ ---        ┆ i64       ┆ ---        ┆ f64     │\n",
       "│ str        ┆            ┆            ┆           ┆ i64        ┆           ┆ f64        ┆         │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪════════════╪═══════════╪════════════╪═════════╡\n",
       "│ Gaming     ┆ 2010-04-29 ┆ UC-lHJZR3G ┆ PewDiePie ┆ 101000000  ┆ 3956      ┆ 3.0        ┆ 2.087   │\n",
       "│            ┆            ┆ qxm24_Vd_A ┆           ┆            ┆           ┆            ┆         │\n",
       "│            ┆            ┆ J5Yw       ┆           ┆            ┆           ┆            ┆         │\n",
       "└────────────┴────────────┴────────────┴───────────┴────────────┴───────────┴────────────┴─────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(ORIGINAL_PATH[\"channels\"], separator='\\t', n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for our further analysis, we need to keep **only** channels with **at least one** of the pre-filtered **videos above**. We compute a simple intersection between IDs of videos above and the channels original dataset. The channel IDs and names are needed to identify the channels in the videos dataset. Subscriber and video counts are also mandatory for having statistical insights. Thus, we will keep the following columns:\n",
    "- `channel` is the channel ID to link with the videos dataset, we will rename it to `channel_id`\n",
    "- `name_cc` is the channel name, which more human-readable and will be renamed to `channel_name`\n",
    "- `subscribers_cc` and `videos_cc` are key indicators of the channel popularity\n",
    "\n",
    "We will also filter out the other categories, and supress the `category_cc` column. We will also drop the `join_date`, `subscriber_rank_sb` and `weight_sb` columns, as they are not relevant for our work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>channel_id</th><th>channel_name</th><th>subscribers</th><th>videos</th></tr><tr><td>str</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;UCzTlXb7ivVzuFlugVCv3Kvg&quot;</td><td>&quot;LDShadowLady&quot;</td><td>4800000</td><td>985</td></tr><tr><td>&quot;UCzUYuC_9XdUUdrnyLii8WYg&quot;</td><td>&quot;All India Bakchod&quot;</td><td>3577841</td><td>142</td></tr><tr><td>&quot;UCzTdZz7z2sPRGCImodwOw0g&quot;</td><td>&quot;JT Music&quot;</td><td>3030000</td><td>678</td></tr><tr><td>&quot;UCzT17-Lvc5L_gIT10JQsjSA&quot;</td><td>&quot;AdelaineMorin&quot;</td><td>2610000</td><td>329</td></tr><tr><td>&quot;UCzUV5283-l5c0oKRtyenj6Q&quot;</td><td>&quot;Mark Dice&quot;</td><td>1500000</td><td>1131</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌──────────────────────────┬───────────────────┬─────────────┬────────┐\n",
       "│ channel_id               ┆ channel_name      ┆ subscribers ┆ videos │\n",
       "│ ---                      ┆ ---               ┆ ---         ┆ ---    │\n",
       "│ str                      ┆ str               ┆ i64         ┆ i64    │\n",
       "╞══════════════════════════╪═══════════════════╪═════════════╪════════╡\n",
       "│ UCzTlXb7ivVzuFlugVCv3Kvg ┆ LDShadowLady      ┆ 4800000     ┆ 985    │\n",
       "│ UCzUYuC_9XdUUdrnyLii8WYg ┆ All India Bakchod ┆ 3577841     ┆ 142    │\n",
       "│ UCzTdZz7z2sPRGCImodwOw0g ┆ JT Music          ┆ 3030000     ┆ 678    │\n",
       "│ UCzT17-Lvc5L_gIT10JQsjSA ┆ AdelaineMorin     ┆ 2610000     ┆ 329    │\n",
       "│ UCzUV5283-l5c0oKRtyenj6Q ┆ Mark Dice         ┆ 1500000     ┆ 1131   │\n",
       "└──────────────────────────┴───────────────────┴─────────────┴────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels_df = pl.read_csv(ORIGINAL_PATH[\"channels\"], separator='\\t')\n",
    "\n",
    "filtered_channels_df = channels_df.filter(pl.col(\"channel\").is_in(filtered_videos_df[\"channel_id\"])).select([\n",
    "    \"channel\",\n",
    "    \"name_cc\",\n",
    "    \"subscribers_cc\",\n",
    "    \"videos_cc\",\n",
    "]).rename({\n",
    "    \"channel\": \"channel_id\",\n",
    "    \"name_cc\": \"channel_name\",\n",
    "    \"subscribers_cc\": \"subscribers\",\n",
    "    \"videos_cc\": \"videos\",\n",
    "})\n",
    "\n",
    "filtered_channels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write the filtered dataset to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_channels_df.write_csv(FILTERED_PATH[\"channels\"], separator='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step of pre-filtering is to treat the **time-series** dataset. It contains the time-series of views and subscribers for each channel. Each data point represents the **view and subsciber count** for a given week. Here is what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>channel</th><th>category</th><th>datetime</th><th>views</th><th>delta_views</th><th>subs</th><th>delta_subs</th><th>videos</th><th>delta_videos</th><th>activity</th></tr><tr><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;UCBJuEqXfXTdcPSbGO9qqn1g&quot;</td><td>&quot;Film and Animation&quot;</td><td>&quot;2017-07-03 00:00:00&quot;</td><td>202494.555556</td><td>0.0</td><td>650.222222</td><td>0.0</td><td>5</td><td>0</td><td>3</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 10)\n",
       "┌────────────┬────────────┬────────────┬───────────┬───┬───────────┬────────┬───────────┬──────────┐\n",
       "│ channel    ┆ category   ┆ datetime   ┆ views     ┆ … ┆ delta_sub ┆ videos ┆ delta_vid ┆ activity │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---       ┆   ┆ s         ┆ ---    ┆ eos       ┆ ---      │\n",
       "│ str        ┆ str        ┆ str        ┆ f64       ┆   ┆ ---       ┆ i64    ┆ ---       ┆ i64      │\n",
       "│            ┆            ┆            ┆           ┆   ┆ f64       ┆        ┆ i64       ┆          │\n",
       "╞════════════╪════════════╪════════════╪═══════════╪═══╪═══════════╪════════╪═══════════╪══════════╡\n",
       "│ UCBJuEqXfX ┆ Film and   ┆ 2017-07-03 ┆ 202494.55 ┆ … ┆ 0.0       ┆ 5      ┆ 0         ┆ 3        │\n",
       "│ TdcPSbGO9q ┆ Animation  ┆ 00:00:00   ┆ 5556      ┆   ┆           ┆        ┆           ┆          │\n",
       "│ qn1g       ┆            ┆            ┆           ┆   ┆           ┆        ┆           ┆          │\n",
       "└────────────┴────────────┴────────────┴───────────┴───┴───────────┴────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(ORIGINAL_PATH[\"timeseries\"], separator='\\t', n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our work, we will keep the following columns, only for the **channels** we selected **above**:\n",
    "- `channel` to link with the videos and channels datasets, it will be renamed to `channel_id`\n",
    "- `datetime` to track the time of the data point\t\n",
    "- `views`, `subs` and `videos` to track the global statistics of the channel\n",
    "- `delta_views`, `delta_subs` and `delta_videos` to track the evolution of the channel\n",
    "\n",
    "However, the columns we are not interested in anymore are `category`, and `activity` which represents the number of videos uploaded in the last 15 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_df = pl.read_csv(ORIGINAL_PATH[\"timeseries\"], separator=\"\\t\")\n",
    "\n",
    "filtered_timeseries_df = timeseries_df.filter(pl.col(\"channel\").is_in(filtered_videos_df[\"channel_id\"])).select([\n",
    "    \"channel\",\n",
    "    \"datetime\",\n",
    "    \"views\",\n",
    "    \"delta_views\",\n",
    "    \"subs\",\n",
    "    \"delta_subs\",\n",
    "    \"videos\",\n",
    "    \"delta_videos\"\n",
    "]).rename({\"channel\": \"channel_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same reasons as mentioned above, we will write this dataset to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_timeseries_df.write_csv(FILTERED_PATH[\"timeseries\"], separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Now is the time to handle the **biggest** dataset of our work: the **comments**. Here is what a comment looks like in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>author</th><th>video_id</th><th>likes</th><th>replies</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>&quot;Gkb1QMHrGvA&quot;</td><td>2</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────┬─────────────┬───────┬─────────┐\n",
       "│ author ┆ video_id    ┆ likes ┆ replies │\n",
       "│ ---    ┆ ---         ┆ ---   ┆ ---     │\n",
       "│ i64    ┆ str         ┆ i64   ┆ i64     │\n",
       "╞════════╪═════════════╪═══════╪═════════╡\n",
       "│ 1      ┆ Gkb1QMHrGvA ┆ 2     ┆ 0       │\n",
       "└────────┴─────────────┴───────┴─────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_csv(ORIGINAL_PATH[\"comments\"], separator='\\t', n_rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The work that needs to be done is to filter out the comments that are **not related** to gaming videos. To do so, we thought of having a set containing all the **gaming video IDs**, and checking for each comment if its video ID is in this list. If it is, we keep the comment, otherwise we drop it.\n",
    "\n",
    "The columns that we will keep are:\n",
    "- `author`, which is the **author's ID**, to ensure we keep track of which user commented on which video\n",
    "- `video_id`, which is the **video's ID**, to link the comments to the videos\n",
    "\n",
    "The `likes` and `replies` columns are not needed for our graphs' generations so we will drop them.\n",
    "\n",
    "Firstly, we generate the set of **gaming video IDs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_display_ids = set(filtered_videos_df.to_pandas()[\"display_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then filter out the comments that are **not related** to gaming videos. Finally, we save the filtered dataset to a `.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pl.scan_csv(ORIGINAL_PATH[\"comments\"], separator='\\t', has_header=True).select([\"author\", \"video_id\"])\n",
    "filtered_comments_df = comments_df.filter(pl.col(\"video_id\").is_in(gaming_display_ids))\n",
    "filtered_comments_df.sink_csv(FILTERED_PATH[\"comments\"], separator=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padawan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
